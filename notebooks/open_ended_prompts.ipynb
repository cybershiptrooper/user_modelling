{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens as tl\n",
    "import sae_lens as sl\n",
    "from utils import load_gemma_saes, get_cache_fwd_and_bwd\n",
    "import torch\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "model_size: Literal[\"2b\", \"9b\"] = \"9b\"\n",
    "LAYERS: Literal[\"all\"] | list[int] = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "model_name = f\"google/gemma-2-{model_size}-it\"\n",
    "model = tl.HookedTransformer.from_pretrained(model_name)\n",
    "\n",
    "if LAYERS == \"all\":\n",
    "    LAYERS = list(range(0, model.cfg.n_layers))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saes = load_gemma_saes(model_size, layers=LAYERS)\n",
    "saes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<start_of_turn>user\n",
    "Tomorrow is my bestie's 16th birthday! What should I bring to the birthday party?\n",
    "<start_of_turn>model\n",
    "That's awesome! To give you the best gift idea, tell me a little about your bestie:\n",
    "\n",
    "* **What are\"\"\"\n",
    "\n",
    "import utils.neel_utils as nutils\n",
    "\n",
    "logits = model.forward(prompt, padding_side=\"left\")[:, -1]\n",
    "nutils.show_df(nutils.create_vocab_df(logits[0], make_probs=True).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
